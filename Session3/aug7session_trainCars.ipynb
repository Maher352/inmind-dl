{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1geJ2RkPPJ51re9rIMypHfglgQ1CKBxN2","authorship_tag":"ABX9TyPqca8eYWk68RxJ1T88Lm0i"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Training CARAVAN"],"metadata":{"id":"7Kbyl7caGaRw"}},{"cell_type":"markdown","source":["##Importing Packages"],"metadata":{"id":"V3IJjWO6GYTy"}},{"cell_type":"code","source":["import os\n","from PIL import Image\n","from torchvision import transforms\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision\n","import torch.nn as nn\n","import torchvision.transforms.functional as TF"],"metadata":{"id":"z61_AId-GYBT","executionInfo":{"status":"ok","timestamp":1723038676492,"user_tz":-180,"elapsed":446,"user":{"displayName":"Maher Abou Dargham","userId":"07562806362716404982"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["##Dataset"],"metadata":{"id":"cBk296Q8GWe2"}},{"cell_type":"code","source":["class CarvanaDataset(Dataset):\n","    def __init__(self, car_folder, mask_folder, transform=None):\n","        self.car_folder = car_folder\n","        self.mask_folder = mask_folder\n","        self.transform = transform\n","        self.car_images = sorted(os.listdir(car_folder))\n","        self.mask_images = sorted(os.listdir(mask_folder))\n","\n","    def __len__(self):\n","        return len(self.car_images)\n","\n","    def __getitem__(self, idx):\n","        car_image_path = os.path.join(self.car_folder, self.car_images[idx])\n","        mask_image_path = os.path.join(self.mask_folder, self.mask_images[idx].replace(\".jpg\", \"_mask.gif\"))\n","\n","        car_image = np.array(Image.open(car_image_path).convert(\"RGB\"))\n","        mask_image = np.array(Image.open(mask_image_path).convert(\"L\"), dtype = np.float32)  # Convert to grayscale (1 channel)\n","\n","        mask_image = mask_image.point(lambda p: p > 128 and 1)\n","\n","        # Apply the same transformation to both images\n","        if self.transform:\n","            # Ensure the transform is applied in a way that it works for both images\n","            augmentations = self.transform(image = image, mask = mask)\n","            image = augmentations('image')\n","            mask = augmentations('mask')\n","        return car_image, mask_image"],"metadata":{"id":"vYUPHfqLBpdP","executionInfo":{"status":"ok","timestamp":1723038850018,"user_tz":-180,"elapsed":307,"user":{"displayName":"Maher Abou Dargham","userId":"07562806362716404982"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["##Utils"],"metadata":{"id":"tLBgIG2MFJCV"}},{"cell_type":"code","source":["def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n","    print(\"=> Saving checkpoint\")\n","    torch.save(state, filename)\n","\n","def load_checkpoint(checkpoint, model):\n","    print(\"=> Loading checkpoint\")\n","    model.load_state_dict(checkpoint[\"state_dict\"])\n","\n","def get_loaders(\n","    train_dir,\n","    train_maskdir,\n","    val_dir,\n","    val_maskdir,\n","    batch_size,\n","    train_transform,\n","    val_transform,\n","    num_workers=4,\n","    pin_memory=True,\n","):\n","    train_ds = CarvanaDataset(\n","        image_dir=train_dir,\n","        mask_dir=train_maskdir,\n","        transform=train_transform,\n","    )\n","\n","    train_loader = DataLoader(\n","        train_ds,\n","        batch_size=batch_size,\n","        num_workers=num_workers,\n","        pin_memory=pin_memory,\n","        shuffle=True,\n","    )\n","\n","    val_ds = CarvanaDataset(\n","        image_dir=val_dir,\n","        mask_dir=val_maskdir,\n","        transform=val_transform,\n","    )\n","\n","    val_loader = DataLoader(\n","        val_ds,\n","        batch_size=batch_size,\n","        num_workers=num_workers,\n","        pin_memory=pin_memory,\n","        shuffle=False,\n","    )\n","\n","    return train_loader, val_loader\n","\n","def check_accuracy(loader, model, device=\"cuda\"):\n","    num_correct = 0\n","    num_pixels = 0\n","    dice_score = 0\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x = x.to(device)\n","            y = y.to(device).unsqueeze(1)\n","            preds = torch.sigmoid(model(x))\n","            preds = (preds > 0.5).float()\n","            num_correct += (preds == y).sum()\n","            num_pixels += torch.numel(preds)\n","            dice_score += (2 * (preds * y).sum()) / (\n","                (preds + y).sum() + 1e-8\n","            )\n","\n","    print(\n","        f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\"\n","    )\n","    print(f\"Dice score: {dice_score/len(loader)}\")\n","    model.train()\n","\n","def save_predictions_as_imgs(\n","    loader, model, folder=\"saved_images/\", device=\"cuda\"\n","):\n","    model.eval()\n","    for idx, (x, y) in enumerate(loader):\n","        x = x.to(device=device)\n","        with torch.no_grad():\n","            preds = torch.sigmoid(model(x))\n","            preds = (preds > 0.5).float()\n","        torchvision.utils.save_image(\n","            preds, f\"{folder}/pred_{idx}.png\"\n","        )\n","        torchvision.utils.save_image(y.unsqueeze(1), f\"{folder}{idx}.png\")\n","\n","    model.train()"],"metadata":{"id":"JwmtA3QCFKV-","executionInfo":{"status":"ok","timestamp":1723038676818,"user_tz":-180,"elapsed":9,"user":{"displayName":"Maher Abou Dargham","userId":"07562806362716404982"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["##Model"],"metadata":{"id":"s4kAkPJXFUEc"}},{"cell_type":"code","source":["class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(DoubleConv, self).__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","class UNET(nn.Module):\n","    def __init__(\n","            self, in_channels=3, out_channels=1, features=[64, 128, 256, 512],\n","    ):\n","        super(UNET, self).__init__()\n","        self.ups = nn.ModuleList()\n","        self.downs = nn.ModuleList()\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        # Down part of UNET\n","        for feature in features:\n","            self.downs.append(DoubleConv(in_channels, feature))\n","            in_channels = feature\n","\n","        # Up part of UNET\n","        for feature in reversed(features):\n","            self.ups.append(\n","                nn.ConvTranspose2d(\n","                    feature*2, feature, kernel_size=2, stride=2,\n","                )\n","            )\n","            self.ups.append(DoubleConv(feature*2, feature))\n","\n","        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n","        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        skip_connections = []\n","\n","        for down in self.downs:\n","            x = down(x)\n","            skip_connections.append(x)\n","            x = self.pool(x)\n","\n","        x = self.bottleneck(x)\n","        skip_connections = skip_connections[::-1]\n","\n","        for idx in range(0, len(self.ups), 2):\n","            x = self.ups[idx](x)\n","            skip_connection = skip_connections[idx//2]\n","\n","            if x.shape != skip_connection.shape:\n","                x = TF.resize(x, size=skip_connection.shape[2:])\n","\n","            concat_skip = torch.cat((skip_connection, x), dim=1)\n","            x = self.ups[idx+1](concat_skip)\n","\n","        return self.final_conv(x)\n","\n","def test():\n","    x = torch.randn((3, 1, 161, 161))\n","    model = UNET(in_channels=1, out_channels=1)\n","    preds = model(x)\n","    assert preds.shape == x.shape\n","\n","if __name__ == \"__main__\":\n","    test()"],"metadata":{"id":"eRcYfXjDFVSE","executionInfo":{"status":"ok","timestamp":1723038681516,"user_tz":-180,"elapsed":4706,"user":{"displayName":"Maher Abou Dargham","userId":"07562806362716404982"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["##Train"],"metadata":{"id":"JhZOUCnOG97h"}},{"cell_type":"code","source":[],"metadata":{"id":"-K_8cOVmG_ZI"},"execution_count":null,"outputs":[]}]}