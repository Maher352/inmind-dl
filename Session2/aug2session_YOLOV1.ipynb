{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO1Nc8QF+KiyhNYb8FurTLe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"eLSAM6LJAmTd","executionInfo":{"status":"ok","timestamp":1723015045194,"user_tz":-180,"elapsed":7720,"user":{"displayName":"Maher Abou Dargham","userId":"07562806362716404982"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchsummary"]},{"cell_type":"code","source":["class ConvLayering(nn.Module):\n","  def __init__(self, in_channels, num_filters, kernel_size, stride=1, padding=0):\n","    super(ConvLayering, self).__init__()\n","\n","    self.conv = nn.Conv2d(in_channels, num_filters, kernel_size = kernel_size, stride = stride, padding = padding)\n","    self.batchnorm = nn.BatchNorm2d(num_filters)\n","    self.leaky_relu = nn.LeakyReLU(0.01)\n","\n","  def forward(self, x):\n","    x = self.conv(x)\n","    x = self.batchnorm(x)\n","    x = self.leaky_relu(x)\n","    return x\n","\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        #first layer\n","        self.convLayer1 = ConvLayering(3, 64, 7, 2, 3)\n","        #maxPool1\n","\n","        #second layer\n","        self.convLayer2 = ConvLayering(64, 192, 3, 1, 1)\n","        #maxPool2\n","\n","        #third layer\n","        self.convLayer3 = ConvLayering(192, 128, 1)\n","        self.convLayer4 = ConvLayering(128, 256, 3, 1, 1)\n","        self.convLayer5 = ConvLayering(256, 256, 1)\n","        self.convLayer6 = ConvLayering(256, 512, 3, 1, 1)\n","        #maxPool3\n","\n","        #fourth layer\n","        #4x\n","        self.convLayer7 = ConvLayering(512, 256, 1)\n","        self.convLayer8 = ConvLayering(256, 512, 3, 1, 1)\n","        self.convLayer9 = ConvLayering(512, 256, 1)\n","        self.convLayer10 = ConvLayering(256, 512, 3, 1, 1)\n","        self.convLayer11 = ConvLayering(512, 256, 1)\n","        self.convLayer12 = ConvLayering(256, 512, 3, 1, 1)\n","        self.convLayer13 = ConvLayering(512, 256, 1)\n","        self.convLayer14 = ConvLayering(256, 512, 3, 1, 1)\n","\n","        self.convLayer15 = ConvLayering(512, 512, 1)\n","        self.convLayer16 = ConvLayering(512, 1024, 3, 1, 1)\n","        #maxPool4\n","\n","        #fifth layer\n","        #2x\n","        self.convLayer17 = ConvLayering(1024, 512, 1)\n","        self.convLayer18 = ConvLayering(512, 1024, 3, 1, 1)\n","        self.convLayer19 = ConvLayering(1024, 512, 1)\n","        self.convLayer20 = ConvLayering(512, 1024, 3, 1, 1)\n","\n","        self.convLayer21 = ConvLayering(1024, 1024, 3, 1, 1)\n","        self.convLayer22 = ConvLayering(1024, 1024, 3, 2, 1)\n","        #no maxPool\n","\n","        #sixth layer\n","        self.convLayer23 = ConvLayering(1024, 1024, 3, 1, 1)\n","        self.convLayer24 = ConvLayering(1024, 1024, 3, 1, 1)\n","        #no maxPool\n","\n","        #seventh layer\n","        self.fc1 = nn.Linear(50176, 4096)\n","\n","        #eighth layer\n","        self.fc2 = nn.Linear(4096, 1470)\n","\n","\n","        #max pooling\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        #activation functions\n","        self.leaky_relu = nn.LeakyReLU(0.01)\n","\n","        #flatten\n","        self.flatten = nn.Flatten()\n","\n","    def forward(self, x):\n","        x = self.convLayer1(x)\n","        x = self.pool(x)\n","        #print(\"layer1 complete\")\n","\n","        x = self.convLayer2(x)\n","        x = self.pool(x)\n","        #print(\"layer2 complete\")\n","\n","        x = self.convLayer3(x)\n","        x = self.convLayer4(x)\n","        x = self.convLayer5(x)\n","        x = self.convLayer6(x)\n","        x = self.pool(x)\n","        #print(\"layer3 complete\")\n","\n","        x = self.convLayer7(x)\n","        x = self.convLayer8(x)\n","        x = self.convLayer9(x)\n","        x = self.convLayer10(x)\n","        x = self.convLayer11(x)\n","        x = self.convLayer12(x)\n","        x = self.convLayer13(x)\n","        x = self.convLayer14(x)\n","        x = self.convLayer15(x)\n","        x = self.convLayer16(x)\n","        x = self.pool(x)\n","        #print(\"layer4 complete\")\n","\n","        x = self.convLayer17(x)\n","        x = self.convLayer18(x)\n","        x = self.convLayer19(x)\n","        x = self.convLayer20(x)\n","        x = self.convLayer21(x)\n","        x = self.convLayer22(x)\n","        #print(\"layer5 complete\")\n","\n","        x = self.convLayer23(x)\n","        x = self.convLayer24(x)\n","        x = self.flatten(x)\n","        #print(x.shape)\n","        #print(\"layer6 complete\")\n","\n","        x = self.leaky_relu(self.fc1(x))\n","        #print(\"layer7 complete\")\n","\n","        x = self.fc2(x)\n","        #print(\"layer8 complete\")\n","\n","        return x"],"metadata":{"id":"pmO5Rk7RL-mP","executionInfo":{"status":"ok","timestamp":1723015272395,"user_tz":-180,"elapsed":324,"user":{"displayName":"Maher Abou Dargham","userId":"07562806362716404982"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Initialize the YoloV1 network\n","model = CNN()\n","\n","sample_input = torch.randint(0, 2, (4, 3, 448, 448), dtype=torch.float32) # (batches, channels, height, width)\n","sample_output = model(sample_input).detach()\n","\n","# Print the output\n","print(\"Model input:\")\n","print(sample_input.shape, \"\\n\", sample_input)\n","print(\"Model output:\")\n","print(sample_output.shape, \"\\n\", sample_output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NfZA7i4VPe1o","executionInfo":{"status":"ok","timestamp":1723015282791,"user_tz":-180,"elapsed":6512,"user":{"displayName":"Maher Abou Dargham","userId":"07562806362716404982"}},"outputId":"a900e056-34a3-4e05-9aa7-57180f13f3d1"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Model input:\n","torch.Size([4, 3, 448, 448]) \n"," tensor([[[[1., 1., 0.,  ..., 0., 1., 0.],\n","          [1., 1., 0.,  ..., 1., 1., 0.],\n","          [1., 1., 0.,  ..., 0., 0., 0.],\n","          ...,\n","          [0., 1., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 1.,  ..., 1., 1., 0.],\n","          [1., 0., 1.,  ..., 0., 0., 0.]],\n","\n","         [[1., 0., 0.,  ..., 1., 0., 0.],\n","          [1., 0., 1.,  ..., 1., 0., 1.],\n","          [0., 0., 0.,  ..., 0., 0., 1.],\n","          ...,\n","          [0., 0., 0.,  ..., 1., 1., 0.],\n","          [0., 0., 1.,  ..., 1., 0., 1.],\n","          [0., 1., 1.,  ..., 0., 0., 1.]],\n","\n","         [[1., 1., 1.,  ..., 1., 0., 0.],\n","          [0., 1., 1.,  ..., 0., 0., 0.],\n","          [0., 1., 1.,  ..., 0., 1., 1.],\n","          ...,\n","          [1., 1., 1.,  ..., 0., 1., 0.],\n","          [0., 0., 0.,  ..., 1., 1., 0.],\n","          [1., 1., 0.,  ..., 0., 0., 1.]]],\n","\n","\n","        [[[1., 1., 0.,  ..., 0., 1., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 1.],\n","          [1., 1., 0.,  ..., 0., 1., 1.],\n","          ...,\n","          [0., 1., 1.,  ..., 1., 0., 1.],\n","          [0., 0., 1.,  ..., 1., 0., 0.],\n","          [1., 1., 0.,  ..., 0., 0., 1.]],\n","\n","         [[0., 1., 1.,  ..., 0., 1., 1.],\n","          [1., 0., 1.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 1., 1., 0.],\n","          ...,\n","          [1., 1., 1.,  ..., 1., 0., 1.],\n","          [1., 1., 1.,  ..., 0., 0., 1.],\n","          [0., 1., 1.,  ..., 1., 0., 0.]],\n","\n","         [[1., 1., 1.,  ..., 1., 1., 0.],\n","          [1., 1., 1.,  ..., 1., 0., 1.],\n","          [0., 0., 0.,  ..., 1., 0., 0.],\n","          ...,\n","          [0., 1., 1.,  ..., 0., 1., 0.],\n","          [1., 0., 1.,  ..., 1., 0., 1.],\n","          [0., 1., 1.,  ..., 1., 0., 0.]]],\n","\n","\n","        [[[0., 1., 0.,  ..., 1., 0., 1.],\n","          [0., 0., 0.,  ..., 1., 1., 0.],\n","          [1., 0., 1.,  ..., 0., 0., 1.],\n","          ...,\n","          [0., 1., 1.,  ..., 1., 1., 1.],\n","          [0., 0., 0.,  ..., 0., 1., 0.],\n","          [0., 0., 1.,  ..., 1., 0., 0.]],\n","\n","         [[1., 1., 0.,  ..., 1., 1., 1.],\n","          [1., 1., 0.,  ..., 0., 0., 1.],\n","          [1., 1., 1.,  ..., 0., 0., 0.],\n","          ...,\n","          [0., 0., 1.,  ..., 0., 0., 0.],\n","          [0., 0., 1.,  ..., 1., 1., 0.],\n","          [1., 0., 0.,  ..., 0., 0., 1.]],\n","\n","         [[0., 1., 0.,  ..., 1., 0., 0.],\n","          [1., 0., 0.,  ..., 1., 0., 0.],\n","          [1., 1., 1.,  ..., 0., 0., 0.],\n","          ...,\n","          [1., 0., 0.,  ..., 0., 1., 0.],\n","          [0., 1., 0.,  ..., 0., 1., 0.],\n","          [0., 0., 0.,  ..., 1., 1., 0.]]],\n","\n","\n","        [[[1., 1., 0.,  ..., 0., 0., 1.],\n","          [1., 1., 0.,  ..., 1., 0., 1.],\n","          [0., 1., 0.,  ..., 1., 0., 0.],\n","          ...,\n","          [0., 1., 0.,  ..., 1., 1., 1.],\n","          [0., 0., 1.,  ..., 0., 1., 0.],\n","          [0., 0., 0.,  ..., 0., 1., 0.]],\n","\n","         [[0., 1., 1.,  ..., 0., 1., 1.],\n","          [0., 1., 0.,  ..., 0., 1., 1.],\n","          [1., 1., 0.,  ..., 0., 1., 0.],\n","          ...,\n","          [1., 0., 1.,  ..., 1., 1., 0.],\n","          [0., 1., 1.,  ..., 0., 0., 1.],\n","          [0., 1., 0.,  ..., 1., 1., 0.]],\n","\n","         [[1., 0., 0.,  ..., 1., 0., 0.],\n","          [1., 0., 1.,  ..., 1., 0., 1.],\n","          [1., 0., 1.,  ..., 1., 0., 1.],\n","          ...,\n","          [0., 0., 1.,  ..., 1., 0., 0.],\n","          [1., 1., 1.,  ..., 0., 0., 1.],\n","          [0., 0., 1.,  ..., 1., 0., 0.]]]])\n","Model output:\n","torch.Size([4, 1470]) \n"," tensor([[-0.0135, -0.2290,  0.1507,  ...,  0.0437, -0.2848,  0.1407],\n","        [ 0.0689,  0.0174,  0.0519,  ..., -0.1076, -0.2356,  0.2767],\n","        [ 0.1169,  0.0338,  0.1567,  ...,  0.0574, -0.2690,  0.1467],\n","        [-0.1415, -0.0288,  0.0018,  ..., -0.0829, -0.2600, -0.0926]])\n"]}]},{"cell_type":"code","source":["# Print the summary\n","torchsummary.summary(model, input_size=(3, 448, 448))  # (channels, height, width)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"elAY0oy9tKfY","executionInfo":{"status":"ok","timestamp":1723015306224,"user_tz":-180,"elapsed":2359,"user":{"displayName":"Maher Abou Dargham","userId":"07562806362716404982"}},"outputId":"3228c650-5292-4b56-9406-d99fb665d1d2"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 224, 224]           9,472\n","       BatchNorm2d-2         [-1, 64, 224, 224]             128\n","         LeakyReLU-3         [-1, 64, 224, 224]               0\n","      ConvLayering-4         [-1, 64, 224, 224]               0\n","         MaxPool2d-5         [-1, 64, 112, 112]               0\n","            Conv2d-6        [-1, 192, 112, 112]         110,784\n","       BatchNorm2d-7        [-1, 192, 112, 112]             384\n","         LeakyReLU-8        [-1, 192, 112, 112]               0\n","      ConvLayering-9        [-1, 192, 112, 112]               0\n","        MaxPool2d-10          [-1, 192, 56, 56]               0\n","           Conv2d-11          [-1, 128, 56, 56]          24,704\n","      BatchNorm2d-12          [-1, 128, 56, 56]             256\n","        LeakyReLU-13          [-1, 128, 56, 56]               0\n","     ConvLayering-14          [-1, 128, 56, 56]               0\n","           Conv2d-15          [-1, 256, 56, 56]         295,168\n","      BatchNorm2d-16          [-1, 256, 56, 56]             512\n","        LeakyReLU-17          [-1, 256, 56, 56]               0\n","     ConvLayering-18          [-1, 256, 56, 56]               0\n","           Conv2d-19          [-1, 256, 56, 56]          65,792\n","      BatchNorm2d-20          [-1, 256, 56, 56]             512\n","        LeakyReLU-21          [-1, 256, 56, 56]               0\n","     ConvLayering-22          [-1, 256, 56, 56]               0\n","           Conv2d-23          [-1, 512, 56, 56]       1,180,160\n","      BatchNorm2d-24          [-1, 512, 56, 56]           1,024\n","        LeakyReLU-25          [-1, 512, 56, 56]               0\n","     ConvLayering-26          [-1, 512, 56, 56]               0\n","        MaxPool2d-27          [-1, 512, 28, 28]               0\n","           Conv2d-28          [-1, 256, 28, 28]         131,328\n","      BatchNorm2d-29          [-1, 256, 28, 28]             512\n","        LeakyReLU-30          [-1, 256, 28, 28]               0\n","     ConvLayering-31          [-1, 256, 28, 28]               0\n","           Conv2d-32          [-1, 512, 28, 28]       1,180,160\n","      BatchNorm2d-33          [-1, 512, 28, 28]           1,024\n","        LeakyReLU-34          [-1, 512, 28, 28]               0\n","     ConvLayering-35          [-1, 512, 28, 28]               0\n","           Conv2d-36          [-1, 256, 28, 28]         131,328\n","      BatchNorm2d-37          [-1, 256, 28, 28]             512\n","        LeakyReLU-38          [-1, 256, 28, 28]               0\n","     ConvLayering-39          [-1, 256, 28, 28]               0\n","           Conv2d-40          [-1, 512, 28, 28]       1,180,160\n","      BatchNorm2d-41          [-1, 512, 28, 28]           1,024\n","        LeakyReLU-42          [-1, 512, 28, 28]               0\n","     ConvLayering-43          [-1, 512, 28, 28]               0\n","           Conv2d-44          [-1, 256, 28, 28]         131,328\n","      BatchNorm2d-45          [-1, 256, 28, 28]             512\n","        LeakyReLU-46          [-1, 256, 28, 28]               0\n","     ConvLayering-47          [-1, 256, 28, 28]               0\n","           Conv2d-48          [-1, 512, 28, 28]       1,180,160\n","      BatchNorm2d-49          [-1, 512, 28, 28]           1,024\n","        LeakyReLU-50          [-1, 512, 28, 28]               0\n","     ConvLayering-51          [-1, 512, 28, 28]               0\n","           Conv2d-52          [-1, 256, 28, 28]         131,328\n","      BatchNorm2d-53          [-1, 256, 28, 28]             512\n","        LeakyReLU-54          [-1, 256, 28, 28]               0\n","     ConvLayering-55          [-1, 256, 28, 28]               0\n","           Conv2d-56          [-1, 512, 28, 28]       1,180,160\n","      BatchNorm2d-57          [-1, 512, 28, 28]           1,024\n","        LeakyReLU-58          [-1, 512, 28, 28]               0\n","     ConvLayering-59          [-1, 512, 28, 28]               0\n","           Conv2d-60          [-1, 512, 28, 28]         262,656\n","      BatchNorm2d-61          [-1, 512, 28, 28]           1,024\n","        LeakyReLU-62          [-1, 512, 28, 28]               0\n","     ConvLayering-63          [-1, 512, 28, 28]               0\n","           Conv2d-64         [-1, 1024, 28, 28]       4,719,616\n","      BatchNorm2d-65         [-1, 1024, 28, 28]           2,048\n","        LeakyReLU-66         [-1, 1024, 28, 28]               0\n","     ConvLayering-67         [-1, 1024, 28, 28]               0\n","        MaxPool2d-68         [-1, 1024, 14, 14]               0\n","           Conv2d-69          [-1, 512, 14, 14]         524,800\n","      BatchNorm2d-70          [-1, 512, 14, 14]           1,024\n","        LeakyReLU-71          [-1, 512, 14, 14]               0\n","     ConvLayering-72          [-1, 512, 14, 14]               0\n","           Conv2d-73         [-1, 1024, 14, 14]       4,719,616\n","      BatchNorm2d-74         [-1, 1024, 14, 14]           2,048\n","        LeakyReLU-75         [-1, 1024, 14, 14]               0\n","     ConvLayering-76         [-1, 1024, 14, 14]               0\n","           Conv2d-77          [-1, 512, 14, 14]         524,800\n","      BatchNorm2d-78          [-1, 512, 14, 14]           1,024\n","        LeakyReLU-79          [-1, 512, 14, 14]               0\n","     ConvLayering-80          [-1, 512, 14, 14]               0\n","           Conv2d-81         [-1, 1024, 14, 14]       4,719,616\n","      BatchNorm2d-82         [-1, 1024, 14, 14]           2,048\n","        LeakyReLU-83         [-1, 1024, 14, 14]               0\n","     ConvLayering-84         [-1, 1024, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]       9,438,208\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","        LeakyReLU-87         [-1, 1024, 14, 14]               0\n","     ConvLayering-88         [-1, 1024, 14, 14]               0\n","           Conv2d-89           [-1, 1024, 7, 7]       9,438,208\n","      BatchNorm2d-90           [-1, 1024, 7, 7]           2,048\n","        LeakyReLU-91           [-1, 1024, 7, 7]               0\n","     ConvLayering-92           [-1, 1024, 7, 7]               0\n","           Conv2d-93           [-1, 1024, 7, 7]       9,438,208\n","      BatchNorm2d-94           [-1, 1024, 7, 7]           2,048\n","        LeakyReLU-95           [-1, 1024, 7, 7]               0\n","     ConvLayering-96           [-1, 1024, 7, 7]               0\n","           Conv2d-97           [-1, 1024, 7, 7]       9,438,208\n","      BatchNorm2d-98           [-1, 1024, 7, 7]           2,048\n","        LeakyReLU-99           [-1, 1024, 7, 7]               0\n","    ConvLayering-100           [-1, 1024, 7, 7]               0\n","         Flatten-101                [-1, 50176]               0\n","          Linear-102                 [-1, 4096]     205,524,992\n","       LeakyReLU-103                 [-1, 4096]               0\n","          Linear-104                 [-1, 1470]       6,022,590\n","================================================================\n","Total params: 271,729,918\n","Trainable params: 271,729,918\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 2.30\n","Forward/backward pass size (MB): 436.86\n","Params size (MB): 1036.57\n","Estimated Total Size (MB): 1475.73\n","----------------------------------------------------------------\n"]}]}]}